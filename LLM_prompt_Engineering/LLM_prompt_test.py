import openai
import os
import logging
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(
    filename="chat_log.txt",
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
    encoding="utf-8"
)

# GPT ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (LLM_Prompt)
def get_gpt_response(user_message):
    messages = [
        {"role": "system", "content": "ë„ˆëŠ” ëŒ€í•™ìƒì´ì•¼. ê°•ì›ëŒ€í•™êµ í•™ìƒì´ê¸°ë„ í•˜ê³ . ëˆ„ê°€ ë¬¼ì–´ë³´ë©´ ê·¸ëƒ¥ ê°•ì›ëŒ€í•™êµ í•™ìƒì´ë¼ê³  í•´."},
        {"role": "user", "content": user_message}
    ]
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",  # ë˜ëŠ” "gpt-4"
        messages=messages
    )
    return response.choices[0].message.content.strip()

def main():
    print("GPT ì±„íŒ… ì‹œì‘! 'ì¢…ë£Œ' ì…ë ¥ ì‹œ ì¢…ë£Œ\n")

    while True:
        user_input = input("ì§ˆë¬¸ì: ")
        if user_input.lower() in ["ì¢…ë£Œ"]:
            print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # GPT ì‘ë‹µ ìƒì„±
        bot_response = get_gpt_response(user_input)
        print(f"ğŸ¤– ê°•ê°•ê°€ì˜¨: {bot_response}\n")

        # ë¡œê·¸ íŒŒì¼ ì €ì¥ (ìœ ì € + GPT)
        with open("chat_log.txt", "a", encoding="utf-8") as log_file:
            log_file.write(f"ì§ˆë¬¸ì: {user_input}\n")
            log_file.write(f"ê°•ê°€ì˜¨: {bot_response}\n\n")

if __name__ == "__main__":
    main()
